

from sqlite3 import connect
import statsmodels.api as sm
import numpy as np
import pandas as pd
import constants as C
import matplotlib.pyplot as plt
from scipy.stats.mstats import winsorize
import pandas_profiling
import statsmodels.formula.api as smf


def get_master(MAIN):
    master = pd.read_sql("select * from master_edited", MAIN, index_col='index')

    # Mapping for renaming the colums for profiling
    useful_columns = [
        'price_minus_one_day',
        'volume_minus_one_day',
        'shares_outstanding_minus_one_day',
        'median_filing_period_returns', 
        'median_filing_period_value_weighted_returns',
        'number_of_words', 
        'percent_negative',
        'book_value_per_share',
        'ff_industry',
        'turnover',
        'year',
        'quater',
    ]

    # Select only specific columns
    master = master[useful_columns]


    # Calculate base values and cast types
    master['book_value_per_share'] = master['book_value_per_share'].astype(float)
    # Price per share * shares outstanding
    master['size'] = master.price_minus_one_day * master.shares_outstanding_minus_one_day
    #  Book Value Per Share / Price per share
    master['book_to_market'] = master.book_value_per_share / master.price_minus_one_day


    # FILTERING

    # Book-to-market COMPUSTAT data available and book value>0
    master = master[master['book_to_market'] > 0]
    # Price on filing date day minus oneâ‰¥$3
    master = master[master['price_minus_one_day'] >= 3]
    # Number of words in 10-K >= 2,000
    master = master[master['number_of_words'] >= 2000]

    # Eliminate all rows containing infinite and not nan values 
    master.replace([np.inf, -np.inf], np.nan, inplace=True)
    master = master.dropna(how='any')


    # WINSORIZE

    # we winsorize the book-to-market variable at the 1% level.
    master['book_to_market'] = winsorize(master['book_to_market'], limits=(0.01, 0.01))
    # master['percent_negative'] = winsorize(master['percent_negative'], limits=(0.01, 0.01))
    # master['median_filing_period_returns'] = winsorize(master['median_filing_period_returns'], limits=(0.01, 0.01))
    # master['turnover'] = winsorize(master['turnover'], limits=(0.01, 0.01))
    # master['size'] = winsorize(master['size'], limits=(0.01, 0.01))


    # LOG

    # Use log values for regression
    master['log_size'] = np.log(master['size'])
    master['log_book_to_market'] = np.log(master['book_to_market'])
    master['log_turnover'] = np.log(master['turnover'])

    # Create 48 - 1 FF industry dummies
    master = pd.concat([master, pd.get_dummies(master['ff_industry'], drop_first=True)], axis=1)

    return master


def ols_coef(section, outcome_var, predictor_vars):
    X = section[predictor_vars]
    y = section[outcome_var]
    X = sm.add_constant(X)
    model = sm.OLS(y, X).fit()
    series = model.params
    # Add r_squared so we can take the mean later
    series['r_squared'] = model.rsquared
    return series


def fama_macbeth(master):
    ff_categories = [str(n) for n in range(2, 49)]
    outcome_var = 'median_filing_period_returns'
    predictor_vars = ['percent_negative', 'log_size', 'log_turnover', 'log_book_to_market']
    profiling_vars = predictor_vars + [outcome_var, 'median_filing_period_value_weighted_returns', 'size', 'book_to_market', 'turnover']
    predictor_vars.extend(ff_categories)
    
    cross_sections = master.groupby(by=['year', 'quater'])
    cross_section_results = cross_sections.apply(ols_coef, outcome_var, predictor_vars)
    print(cross_section_results)
    """
                  const  percent_negative  log_size  log_turnover  log_book_to_market             2             3             4  ...        42        43        44        45        46        47        48  r_squared
year   quater                                                                                                                    ...                                                                                 
2008.0 1.0     0.000842         -0.002572 -0.001689      0.001639           -0.004630  8.354273e-19  0.000000e+00  0.000000e+00  ...  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000476   1.000000
2009.0 1.0     0.048495         -0.004283 -0.002575     -0.002438           -0.000795  1.355428e-02  1.498884e-02  1.135995e-02  ...  0.017907  0.007389 -0.003277  0.001614  0.000256 -0.010222 -0.002605   0.089695
       2.0    -0.032137          0.000611  0.000323      0.003408            0.003314  7.666648e-03  3.528493e-03  3.423765e-02  ...  0.008010  0.014926  0.007347  0.030558 -0.004255 -0.005423  0.008751   0.237924
       3.0    -0.038167         -0.000255  0.001101      0.002849            0.002818  7.397924e-03  1.443588e-02  1.595838e-02  ...  0.002992 -0.009991  0.012799  0.000000 -0.001696  0.008502 -0.013692   0.183385
       4.0    -0.019889         -0.001584 -0.000063      0.001936            0.000662  6.503013e-03 -1.612837e-15 -8.271267e-16  ...  0.009267  0.023629  0.013998  0.000000  0.033740  0.010033  0.008154   0.163618
2010.0 1.0     0.001388          0.000989  0.000361      0.000616            0.000227 -1.349083e-02 -1.064536e-02 -6.407187e-03  ... -0.006716 -0.006202 -0.010566 -0.009491 -0.009528 -0.012072 -0.009906   0.046950
       2.0    -0.031191          0.003940  0.001051     -0.001131            0.004741  2.560372e-02  2.943893e-02  2.487784e-02  ...  0.021615  0.024697  0.019215  0.027666  0.010374  0.025201  0.022628   0.265763
       3.0     0.004297         -0.000044 -0.000296     -0.000475            0.000813  5.456395e-03  3.877758e-03  5.002937e-03  ...  0.005414  0.000504 -0.000289  0.000000  0.012738  0.006286 -0.004208   0.161681
       4.0    -0.001552          0.000671  0.000491      0.000008            0.003090 -1.007581e-02 -1.020331e-16 -2.047969e-17  ... -0.001538  0.001882 -0.001532  0.000000  0.019890 -0.003549  0.000000   0.154782
2011.0 1.0    -0.010431          0.000076  0.000841     -0.000660            0.000517  2.686873e-03  2.691806e-03  7.649361e-03  ...  0.005477  0.003646  0.008227  0.005851  0.001813  0.004840 -0.001152   0.040257
       2.0    -0.004370          0.000836  0.000833     -0.001404            0.001904  9.932226e-03 -3.623740e-03 -2.014056e-03  ...  0.004280  0.002153  0.009114 -0.006832 -0.008285 -0.003289  0.005403   0.182974
       3.0     0.006998         -0.001072  0.002174     -0.004125           -0.000824 -6.020988e-04 -1.308524e-02 -3.228331e-02  ... -0.001193 -0.006608 -0.015421  0.000000 -0.037825 -0.034192 -0.017674   0.209284
       4.0    -0.003152         -0.007326 -0.000201      0.002481            0.001129 -3.812202e-03 -3.100810e-16  2.380568e-16  ...  0.000743  0.004220 -0.005779  0.000000  0.000000  0.013376 -0.008449   0.177986
2012.0 1.0    -0.001193         -0.000551  0.000433     -0.001161            0.000232  8.390070e-03  4.424259e-03  2.937064e-03  ...  0.003763  0.003554  0.003373  0.002033  0.008316  0.000742  0.002293   0.039744
       2.0    -0.019219          0.003605  0.001418     -0.000395           -0.000447  8.372668e-03 -7.734182e-18 -6.876655e-03  ...  0.002059  0.011283 -0.000287  0.004965 -0.006516 -0.007214 -0.009029   0.182098
       3.0    -0.004039          0.001589 -0.001386      0.002603           -0.001896  2.768867e-03  2.901305e-04 -2.046284e-17  ...  0.002203 -0.004537  0.026865  0.000000  0.010718  0.008753  0.013092   0.281102
       4.0    -0.008161         -0.003838  0.001561     -0.001323            0.002635 -5.050757e-03  2.979668e-16 -2.311819e-17  ...  0.002731  0.004271  0.018212 -0.001260  0.000000  0.009788  0.008586   0.259991
2013.0 1.0    -0.003437         -0.000519  0.000402     -0.000568            0.000616  3.146412e-03  4.345299e-03 -5.947395e-03  ...  0.005368  0.004526  0.004397  0.007659 -0.002829  0.002743  0.007177   0.036316
       2.0    -0.000550          0.000416  0.001523     -0.002747            0.000627 -1.224626e-02  8.113006e-19 -6.507602e-03  ...  0.004870  0.004779  0.002365  0.000040 -0.017186 -0.000804  0.004906   0.182244
       3.0    -0.015565          0.000514  0.000282      0.000732           -0.000388  5.331343e-03  9.468900e-03 -1.281789e-16  ...  0.008253  0.007895  0.009359  0.008188  0.007621  0.037282  0.003763   0.138584
       4.0    -0.002830          0.002373  0.000497     -0.001742           -0.000641  3.834194e-03  9.406168e-17  2.485891e-16  ...  0.008137  0.001581 -0.005269  0.003186  0.015887  0.011018  0.002840   0.324104
2014.0 1.0    -0.000828          0.000107  0.000440      0.000010            0.000445 -4.662544e-03 -7.749905e-03 -3.125729e-03  ... -0.003848 -0.002440 -0.005719 -0.001028  0.001320 -0.001267 -0.003742   0.033973
       2.0    -0.003592          0.000650  0.001505     -0.002335            0.000394  2.373300e-03  6.859009e-18 -1.180726e-02  ... -0.000631 -0.001767 -0.001948 -0.014677  0.015602  0.002270 -0.003918   0.172984
       3.0    -0.031296          0.001011  0.000745     -0.001825            0.000312  3.259676e-02  3.045713e-02  4.540376e-17  ...  0.031501  0.032860  0.030142  0.000000  0.000000  0.034743  0.032148   0.186672
       4.0     0.009743          0.006715 -0.001192      0.002192            0.000739 -1.531573e-02  1.045194e-16  7.370177e-17  ... -0.009627 -0.003220 -0.038830 -0.006905 -0.025135 -0.029483 -0.031400   0.124430
2015.0 1.0    -0.001487          0.001269  0.000538     -0.000628            0.001587 -4.219863e-03 -8.932940e-03 -2.218170e-03  ... -0.002372 -0.001270  0.001102 -0.004845 -0.004561 -0.001441 -0.000222   0.029370
       2.0     0.031497          0.000423  0.000708     -0.001577           -0.000167 -3.245042e-02 -3.203671e-02 -3.652259e-02  ... -0.031132 -0.028360 -0.027313 -0.029749  0.000000 -0.025200 -0.030340   0.163104
       3.0    -0.019941          0.004681 -0.000363      0.001768            0.000908  2.464989e-03  1.943697e-02 -2.086515e-16  ...  0.012704 -0.001378  0.006608  0.000000  0.000000  0.022388  0.005213   0.237551
       4.0    -0.015273          0.003228 -0.000035      0.001117           -0.001951  1.077413e-02  1.196704e-02  1.222577e-17  ... -0.003391  0.002509 -0.035925  0.010435  0.000000  0.013642  0.000770   0.242314
2016.0 1.0    -0.016693          0.000609  0.000949      0.001227            0.002735  1.659031e-03 -7.067329e-04 -1.210543e-02  ... -0.001258  0.000390  0.001056 -0.003856  0.009036  0.002358  0.000573   0.072632
       2.0    -0.000661          0.001273  0.000799     -0.001419           -0.000383  2.871756e-03 -6.724665e-03 -8.358355e-03  ...  0.002259 -0.012022  0.005623 -0.016305  0.000000  0.006172 -0.000037   0.147091
       3.0    -0.032830          0.007534 -0.005754      0.010780           -0.004887  2.065500e-02  2.498782e-02  2.012828e-15  ...  0.006786  0.012447  0.035949  0.000000  0.000000  0.021107  0.018124   0.151063
       4.0     0.012364          0.003872 -0.000062      0.000208           -0.000445 -1.389078e-02  1.564847e-16  9.586028e-17  ... -0.013138 -0.010841 -0.031158 -0.018946  0.024041 -0.025684 -0.016332   0.252252
2017.0 1.0     0.014202         -0.001000  0.000485     -0.001399            0.000421 -7.527683e-03 -4.071856e-03 -3.946005e-03  ... -0.007329 -0.012125 -0.010827 -0.011223 -0.011783 -0.009974 -0.005814   0.051446
       2.0     0.004887          0.007826  0.002477     -0.006127            0.005665  5.922740e-03 -7.251546e-18 -1.181102e-02  ... -0.016566  0.003120  0.000000  0.000000  0.000000  0.000000  0.013149   0.603417
       3.0     0.019418         -0.001382  0.000300     -0.003137           -0.001855  1.768479e-03 -1.155023e-02 -5.693057e-19  ... -0.003280 -0.005939  0.003802  0.000000  0.000000 -0.017117 -0.001902   0.232993
       4.0     0.012565         -0.002575  0.002746     -0.006580            0.001234 -2.943220e-03 -7.729009e-16 -1.486560e-16  ...  0.000814 -0.002112  0.027833  0.001658  0.000000  0.010559  0.001760   0.295867
    """
    
    newey_west_df = pd.DataFrame(columns=['variable', 'coef', 'std_err', 'p_values', 't_values'])
    newey_west_df = newey_west_df.set_index(['variable'])
    for column_hat in cross_section_results:
        if column_hat == 'r_squared':
            # This is not supposed to be t tested
            # we saved it only for the average
            continue
        series = cross_section_results[column_hat]
        # Python doesn't accept OLS without X so lets fill it with 1
        X = np.ones((series.shape[0],1))
        y = series
        # Newey-West standard errors with one lag
        model = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags':1})
        row = [
            model.params[0], # coef
            model.bse[0], # std_err
            model.pvalues[0], # p_values
            model.tvalues[0], # t_values
        ]
        newey_west_df.loc[column_hat] = row

    print("Average R-Squared: ", cross_section_results['r_squared'].mean())
    print(newey_west_df)
    """
Average R-Squared:  0.19880104073083585

                        coef   std_err  p_values  t_values
variable                                                  
const              -0.004102  0.002858  0.151159 -1.435450
percent_negative    0.000752  0.000537  0.161909  1.398679
log_size            0.000307  0.000241  0.201967  1.275968
log_turnover       -0.000260  0.000496  0.600079 -0.524287
log_book_to_market  0.000499  0.000334  0.135807  1.491589
2                   0.001769  0.001747  0.311413  1.012262
3                   0.002033  0.001823  0.264948  1.114773
4                  -0.001295  0.002170  0.550745 -0.596644
5                   0.000559  0.000951  0.556464  0.588102
6                   0.001103  0.001866  0.554502  0.591027
7                   0.001760  0.002314  0.446910  0.760576
8                   0.001278  0.001860  0.491880  0.687321
9                  -0.000321  0.001730  0.852843 -0.185493
10                  0.003556  0.001477  0.016067  2.407395
11                  0.002487  0.002148  0.246928  1.157842
12                  0.001980  0.001848  0.283992  1.071394
13                  0.000284  0.001845  0.877688  0.153900
14                  0.001972  0.001519  0.194026  1.298762
15                  0.002523  0.003567  0.479460  0.707172
16                 -0.002133  0.003520  0.544597 -0.605877
17                  0.001607  0.001816  0.376149  0.885015
18                 -0.001848  0.002076  0.373451 -0.890028
19                  0.002681  0.001927  0.164180  1.391150
20                  0.001279  0.002099  0.542326  0.609299
21                  0.000786  0.001576  0.617787  0.498989
22                  0.000425  0.001671  0.799260  0.254305
23                  0.000336  0.001906  0.860138  0.176199
24                  0.001040  0.001668  0.532882  0.623612
25                 -0.001234  0.003286  0.707353 -0.375413
26                  0.000451  0.001351  0.738764  0.333491
27                 -0.001977  0.001403  0.158861 -1.408912
28                 -0.001510  0.001699  0.374307 -0.888434
29                 -0.000838  0.001098  0.445605 -0.762763
30                 -0.001273  0.002177  0.558758 -0.584688
31                  0.000572  0.001519  0.706603  0.376423
32                  0.002085  0.002679  0.436349  0.778373
33                  0.001665  0.002243  0.457867  0.742364
34                  0.001420  0.001587  0.370750  0.895069
35                  0.001356  0.001648  0.410817  0.822457
36                  0.001131  0.001650  0.493031  0.685496
37                  0.001998  0.001675  0.232961  1.192765
38                 -0.001140  0.001551  0.462310 -0.735049
39                  0.001688  0.001578  0.284668  1.069891
40                 -0.001431  0.002108  0.497205 -0.678893
41                  0.001635  0.001717  0.341047  0.952098
42                  0.001760  0.001633  0.281046  1.077973
43                  0.001715  0.001589  0.280426  1.079363
44                  0.001439  0.002477  0.561251  0.580984
45                 -0.000575  0.001764  0.744654 -0.325697
46                  0.001128  0.002075  0.586608  0.543759
47                  0.001753  0.002347  0.455095  0.746948
48                 -0.000017  0.001601  0.991679 -0.010430
"""


def do_analysis(MAIN):
    master = get_master(MAIN)
    fama_macbeth(master)


def main():
    with connect(C.MAIN_DB_NAME) as MAIN:
        do_analysis(MAIN)


if __name__ == '__main__':
    main()